<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="referrer" content="always">
    <title>Smerity.com: Peeking into the neural network architecture used for Google&#39;s Neural Machine Translation</title>
    
  <link rel="shortcut icon" href="/media/images/favicon.ico">

    
  
  <meta property="og:title" content="Peeking into the neural network architecture used for Google&#39;s Neural Machine Translation">
  
  <meta name="description" content="Google&#39;s Neural Machine Translation looks horrifically complex but actually makes a lot of sense if you build it up piece by piece." />
  <meta property="og:description" content="Google&#39;s Neural Machine Translation looks horrifically complex but actually makes a lot of sense if you build it up piece by piece." />
  <meta name="twitter:description" content="Google&#39;s Neural Machine Translation looks horrifically complex but actually makes a lot of sense if you build it up piece by piece." />
  <!-- Seems excessive, doesn't it? -->
  
  
  <meta property="og:site_name" content="Smerity.com" />
  <meta property="og:type" content="article" />
  <meta name="twitter:site" content="@Smerity" />
  <meta name="twitter:creator" content="Smerity" />
  

    
  <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
  <!--[if lt IE 9]>
    <script src="/media/js/html5.js"></script>
  <![endif]-->

  
  <link rel="stylesheet" type="text/css" href="/media/compiled_less/bootstrap.css">

  <link rel="stylesheet" type="text/css" href="/media/css/pygments.css">

    
  <script type="text/javascript" src="/media/js/jquery.js"></script>
  <script src="/media/bootstrap/js/bootstrap.js"></script>
  <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ["\\(","\\)"] ],
          displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
          processEscapes: false,
          skipTags: ["script","noscript","style","textarea","code"]
        }
      });
  </script>
  <script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML">
  </script>


    
    
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-470775-5']);
    _gaq.push(['_trackPageview']);
    setTimeout("_gaq.push(['_trackEvent', '15_seconds', 'read'])",15000);
    setTimeout("_gaq.push(['_trackEvent', '30_seconds', 'read'])",30000);
    setTimeout("_gaq.push(['_trackEvent', '60_seconds', 'read'])",60000);
    setTimeout("_gaq.push(['_trackEvent', '120_seconds', 'read'])",120000);
    setTimeout("_gaq.push(['_trackEvent', '240_seconds', 'read'])",240000);
    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>

  </head>
  <body>
  


  
  
<div class="hero-box">
  <div class="hero-inner min-padded">
    <a href="/">
      <h3 class="heavy pull-left">&laquo; Smerity.com</h3>
    </a>
    <h3 class="maroon contact-me pull-right">
      <!-- All on one line seems crazy but it prevents small form factors trying to fit them over multiple lines -->
      <a href="https://www.twitter.com/Smerity/" alt="Twitter"><i class="icon-twitter"></i></a><a href="https://facebook.com/smerity" alt="Facebook"><i class="icon-facebook-sign"></i></a><a href="https://github.com/Smerity/" alt="GitHub"><i class="icon-github"></i></a><a href="http://au.linkedin.com/in/smerity" alt="LinkedIn"><i class="icon-linkedin"></i></a><a href="mailto:smerity@smerity.com" alt="Email"><i class="icon-envelope-alt"></i></a>
    </h3>
  </div>
</div>

  <div class="container">
    
      <div class="row">
      <div class="span8 content-wrapper ">
        
  

        <div class="content-box">
        
<h1 class="post-title">Peeking into the neural network architecture used for Google&#39;s Neural Machine Translation</h1>
<h3 class="post-date">November 17, 2016</h3>
  <p>The <a href="https://arxiv.org/abs/1609.08144">Google Neural Machine Translation paper</a> (GNMT) describes an interesting approach towards deep learning in production.
The paper and architecture are non-standard, in many cases deviating far from what you might expect from an architecture you'd find in an academic paper.
Emphasis is placed on ensuring the system remains practical rather than chasing the state of the art through typical but computationally intensive tweaks.</p>
<!--**Note:** This article is likely one in a series for GNMT.
There are many potential future article directions and I'd be interested in your feedback.
As an example, we could next discuss what the data (word, wordpiece, character level) actually looks like.
We could delve into the training of the model.
We could discuss BLEU scores and how they try to capture quality in translation.
We could discuss the tweaks 
We could 
-->

<h2>The architecture</h2>
<p>To understand the model used in GNMT we'll start with a traditional encoder decoder machine translation model and keep evolving it until it matches GNMT.
The GNMT evolution seems primarily motivated by improving accuracy while maintaining practical production speeds for both training and prediction.</p>
<h3>V1: Encoder-decoder</h3>
<p>The encoder decoder architecture started the recent neural machine translation trend.
I'd refer to it as old school if it were more than a few years old.
Shockingly, as the name implies, there are two components - an encoder and a decoder.</p>
<p>For a word level encoder-decoder machine translation system, such as the depiction below:</p>
<ul>
<li>Take an RNN - usually an LSTM - and encode a sentence written in language A (English).</li>
<li>The RNN spits out a hidden state, which we refer to as <strong>S</strong>.</li>
<li>This hidden state hopefully represents all the content of the sentence.</li>
<li>This hidden state <strong>S</strong> is then supplied to the decoder, which generates the sentence in language B (German) word by word.</li>
</ul>
<p><img class="center" src="/media/images/articles/2016/gnmt_arch_1_enc_dec.svg"></p>
<!--While a relatively simple model-->

<p>The encoder decoder showcased the potential that neural based machine translation may provide.
Even with modern complex neural machine translation architectures, the majority of them can still be decomposed in terms of the encoder-decoder architecture.</p>
<p>The primary drawback of this architecture is that, like humans, it has limited memory.
<!--As the sequence gets longer, the translation by necessity becomes more and more lossy.-->
That final hidden state of the LSTM, which we call <strong>S</strong>, is where you're trying to cram the entirety of the sentence you have to translate.
<strong>S</strong> is usually only a few hundred units (read: floating point numbers) long - the more you try to force into this fixed dimensionality vector, the more lossy the neural network is forced to be.
Thinking of neural networks in terms of "lossy compression" they're required to perform is sometimes quite useful.</p>
<p>TODO: Bahdanau</p>
<p>While it may work for our relatively short example above, it's likely to begin failing as the sentence gets longer.
The obvious solution would be increasing the hidden size of the LSTM.
Unfortunately, training rapidly becomes impractical if we do this.
As you increase the hidden size <strong>h</strong> of the LSTM, the number of parameters increases quadratically!
You'll either start running out of memory on your GPU or have training take an eternity.</p>
<h3>V2: Attention based encoder-decoder</h3>
<p>How do we solve this problem of not having a large enough hidden state to represent a sentence?
We could turn to a technique humans naturally perform - iterative attention to relevant parts of the source sentence.
If you were translating a long sentence, you'd likely glance back at the source sentence to ensure you're capturing all the details.
We can allow neural networks to do exactly the same.
By storing and referring to the previous outputs of the LSTM we can increase the storage of our neural network without changing the operation of the LSTM.</p>
<p><img class="center" src="/media/images/articles/2016/gnmt_arch_attn.svg"></p>
<p>Briefly (as attention mechanisms are already well covered elsewhere) the idea is, once you have the LSTM outputs from the encoder stored, you query each output asking how relevant they are to the current computation on the decoder side.
Each output from the encoder then gets a score of relevance which we can turn into a probability distribution that sums up to one via the softmax activation.
We can then extract a context vector that's a weighted summation of the encoder outputs depending on how relevant we think they are.</p>
<p><strong>Note:</strong>
You may notice that the direction connection between the encoder and decoder (<strong>S</strong> in our previous architecture) has disappeared.
While many standard encoder-decoder architectures maintain this direct connection, the GNMT architecture decides to remove it.
The GNMT architectures decides to make the attention mechanism the only way that information can be shifted from the encoder side to the decoder side.</p>
<p>TODO: Add visualization of attention mechanism from Bahdanau or distil pub</p>
<h3>V3: Bi-directional encoder layer</h3>
<p>While the attention mechanism allows for retrieving different parts of the sentence depending on the decoding context, there's still an issue.
The attention mechanism is essentially asking the stored outputs of the encoder "are you relevant to this?" and using that to determine what information to extract.
If the encoder outputs don't have sufficient context themselves, they're unlikely able to provide a good answer.</p>
<!--Why force computers, who already have a substantial handicap, to do something the hardest way possible?-->

<p>Adding information about future words, such that the encoder output is determined by words on both the left and the right, is clearly beneficial.
If a full sentence is available, humans would almost certainly use the full context to determine the meaning and context of a word.
Why would we force computers, who are already at a substantial handicap, to not use all available information?</p>
<p><img class="center" src="/media/images/articles/2016/gnmt_arch_1_birnn.svg"></p>
<p>The easiest way to add this bi-directionality is to run two RNNs - one that goes forward over the sentence and another that goes backwards.
Then, for each word, we can either concatenate or add the resulting vector outputs, producing a vector with context from both sides.
A bi-directional encoder becomes even more important if you're translating to or from a language that has a different ordering (i.e. right-to-left).
The GNMT architecture concatenates them - potentially advantageous as that results in the both the forward and backward RNN being only half the size.
Given the bi-directional layer ends up being a bottleneck in GNMT, and the number of parameters in an RNN scale quadratically, this is not an insignificant saving.</p>
<h3>V4: "The deep is for deep learning"</h3>
<p>For many architectures in neural machine translation, increased depth is a key component in accurate models.
The GNMT architecture trends this direction too by adding a large number of layers.
A pretty darn crazy large number of layers - 8 on the encoder and 8 on the decoder for 16 total.
Many state of the art machine translation systems use far less than this.</p>
<p>For the encoder, their model has one bi-directional RNN layer followed by <strong>seven</strong> uni-directional RNN layers.
The decoder has <strong>eight</strong> uni-directional RNN layers.</p>
<p>In most papers I'd have instead expected all of the layers to be bi-directional for improved accuracy.
A model with all bi-directional layers would be expected to get the same or higher results.
The next section explains why the GNMT model variant strayed away from this.</p>
<p><img class="center" src="/media/images/articles/2016/gnmt_arch_deep.svg"></p>
<p>Recurrent neural networks of this depth are highly problematic to train.
Indeed, standard neural networks of this depth are not trivial to train either, and those are relatively simple compared to what happens over the many timesteps.
We'll look to solve this problem in a later variant.</p>
<h3>V5: Parallelization</h3>
<p>A primary motivator for the GNMT architecture was practicality.
This forces some limitations and odd choices when compared to standard encoder-decoder architectures.
For launching a system like GNMT into production, being parallelizable is a requirement.
It makes not only training faster, allowing more experiments, but also makes production deployments faster too.</p>
<p>The graph we've been looking at represents not only the architecture of the machine translation model but also a dependency graph.
To begin computation at one of the nodes, all of the nodes pointing toward you must already have been computed.
Even if you had an infinite amount of computation, you still need to follow the flow of the dependency graph.
As such, you want to minimize any dependencies that may take far more computation than others at a similar level.</p>
<p><img class="center" src="/media/images/articles/2016/gnmt_arch_deep_partial.svg"></p>
<p><strong>Note:</strong> Unshaded nodes have not yet been completed and nodes shaded white have finished their computation.
Layers shaded blue are in the process of being computed or have finished being computed.</p>
<p>This is the reason that only a single bi-directional RNN layer is used.
A bi-directional layer has to run two RNNs - one from left to right and the other from right to left.
This means to compute the first output you have to wait for <code>N</code> computations from the far right hand side to reach you (where <code>N</code> is the length of sequence).</p>
<p>If all layers were bi-directional, the entirety of that layer would have to finish before any later dependencies could start computing.
If we use uni-directional layers however, our computations can be more flexible and more parallel.
In the example above, focusing just on the encoding side, the first four layers are all computing nodes at the same time.
This is only possible as the layer above doesn't rely on all of the nodes in the layer below, only those directly below it.
This would not be possible if these were bi-directional layers.</p>
<p><img class="center" src="/media/images/articles/2016/gnmt_arch_deep.svg"></p>
<p><strong>Parallelization (decoder side):</strong>
Due to the attention mechanism using all the outputs of the encoder side, the decoder side must wait until all of the encoder has finished running.
When the encoder has finished however, the decoder can perform its operations in the same parallel way as the encoder side.
Usually the attention mechanism would use the top most output of the decoder to query the attention mechanism but the GNMT architecture uses the lowest decoder layer for querying the attention mechanism to minimize the dependency graph and allow for maximal parallelization.
In the example above, if we used the topmost decoder layer for attention, we would not have been able to start computing the second output of the decoder yet, as the first output of the decoder is still in progress.</p>
<p><strong>Side note (teacher forcing and training vs production):</strong> During training, we already known what the English sentence should translate to.
This allows us to have higher levels of parallelism than at prediction time.
As we already have all of the correct words (the "known" translation at the bottom right), we can use it in teacher forcing.
Teacher forcing is where you give the neural network the correct answer for the next word even if it would have actually guessed the wrong word.
This makes sense as training will keep forcing the network towards outputting the correct word, so eventually our assumption should hopefully be correct.
This allows you to "cheat" and be computing the second output word while still in the process of computing the first output word.
In the real word, we need to wait to produce each word one by one, as there's no "known" translation.</p>
<!--
**Attention for multiple layers:** I mentioned previously that there's a tweak to the attention mechanism.
The output of the attention mechanism is fed into all of the RNNs on the decoder side.
This means that every layer in the decoder has a dependency on the output of the attention mechanism.
If the attention mechanism used the final output of the encoder, as is standard in basically every other NMT architecture on earth, we'd have to finish computing *all eight* of the encoder layers before we could start computing even the first layer of the decoder.
To remove this dependency and allow for parallelization simultaneously on the encoder and decoder sides, the attention mechanism uses only the output of the bi-directional layer, which is already a bottleneck for all the other computations.
-->

<p><strong>Side note (multiple GPUs):</strong>
This parallelization really only strongly makes sense with multiple GPUs.
In the GNMT paper, their diagrams actually label each of the layers according to the GPU they use.
For the encoder and decoder, they use eight GPUs - essentially one for each layer.
Why doesn't this make as much sense for a single GPU?
Generally a GPU should be hitting high utilization when computing a given layer, assuming you're able to set reasonable batch sizes, network sizes, and sequence lengths.
This work is primarily about re-ordering dependencies such that more computation can be done at once, allowing for better utilization of more devices.
You're hopefully already fully utilizing your single GPU well, so being able to compute more at the same time won't help you if you don't have that computation spare.
If the production deployment was on CPUs, this re-ordering may still be quite beneficial.</p>
<h3>V6: Residuals are the new hotness</h3>
<p>Eight layers is pretty darn deep - at least for recurrent neural networks.
As a general rule of thumb - barring some exceptions or specific constructions - the deeper a network is, the harder it is to train.
While this is for a variety of reasons, the most intuitive is that the further a gradient has to travel, the more it risks vanishing or exploding.
Luckily there are many potential ways to tackle this problem.</p>
<p>One solution for vanishing gradients is residual networks, which has been applied most famously to CNNs such that training neural networks hundreds of layers deep remains feasible.
The idea is relatively simple.
By default, we like the idea of a layer computing an identity function.
This makes sense.
If you do well with one layer, you don't expect a two or three to do worse.
At worst, the second and third layer should just learn to "copy" the output of the first layer - no modifications.
Hence, they just need to learn an identity function.</p>
<p>Unfortunately, learning the identity function seems non-trivial for most networks.
<!--Rather than learning the identity, they usually learn another poor function.-->
Even worse, later layers confuse training of earlier layers as the supervision signal - the direction it's meant to go - keeps shifting.
As such, the first layer may fail to train well at all if there are more layers below it.
To solve this, we bias the architecture of each of these layers towards performing the identity function.</p>
<p><img class="center" src="/media/images/articles/2016/gnmt_arch_res.svg"></p>
<p>We can do this by only allowing the later layers to add deltas (updates) to the existing vector.
Now, if the next layer is lazy and ouputs nothing but zeroes, that's fine, as you'll still have the original vector.</p>
<p>$$
h_1 = f_1(x) \\
h_2 = f_2(h_1) + x \\
h_3 = f_3(h_2) + h_2 = f_3(h_2) + f_2(h_1) + x \\
$$</p>
<h2>The GNMT monster in its full glory (more or less)</h2>
<p>All of these changes build upon their previous iteration to result in the full architecture described in the GNMT paper.
Notice that, while far more complex, it still has the same components of the original encoder-decoder architecture.
It may look scary, but each change is motivated by a relatively simple idea.</p>
<p><img class="center" src="/media/images/articles/2016/gnmt_arch_deep_residuals.svg"></p>
<h2>Conclusion</h2>
<p>The Google Neural Machine Translation architecture is an interesting beast.
While there's nothing tremendously novel in it, the real innovation is the care to which the architecture has been engineered.
If this was a boat, it'd be a chrome speed boat that slices through rough waters with near zero drag.
We're already seeing the architecture used in a variety of contexts, both in translating and generating natural language, likely due to the ability to scale to computationally large and intensive tasks cleanly.
For that reason, I expect to see it pop up in far more places.</p>
<p>This article also contains only a small portion of the paper.
Not discussed here is what BLEU is, how wordpiece level granularity improves translation over word level, advantages/disadvantages of BLEU, quantization of models for faster models during deployment, or jumping between optimization algorithms for better convergence, or that their datasets are so large they don't use dropout!
All of this without mentioning the zero-shot GNMT paper or using the GNMT architecture for conversation models...</p>
<p>Gosh there's a lot to write about!</p>
<hr />
<p>If you like this content, I share similar things on Twitter a few hundred characters at a time ;)</p>
<p><a href="https://twitter.com/Smerity" class="twitter-follow-button" data-size="large" data-show-count="false">Follow @Smerity</a><script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<hr />
<p><strong>My sincere thanks to:</strong></p>
<ul>
<li><a href="https://twitter.com/jekbradbury">James Bradbury</a>, who implemented the world's second best neural machine translation system for English to German while only an intern, and who happily induldges me when I harass him for details :)</li>
<li><a href="https://twitter.com/dennybritz">Denny Britz</a>, who was happy to clarify some points regarding my reading of the GNMT architecture paper! Check out his articles at <a href="http://www.wildml.com/">WildML</a> too!</li>
</ul>

        </div>
      </div>
      
        <div class="span3 side-box">
          <div style="padding: 8px;">
            <h1 style="margin-bottom: 0; text-align: center;">Popular Articles</h1>
            <style>
            ul.unstyled li { padding-bottom: 6px; }
            </style>
            <ul class="crossed">
              <li><a target="_blank" href="/articles/2016/algorithms_can_be_prejudiced.html">It's ML, not magic: machine learning can be prejudiced</a></li>
              <li><a target="_blank" href="/articles/2016/ml_not_magic.html">It's ML, not magic: the rise of AI-prefix investing</a></li>
              <li><a target="_blank" href="/articles/2016/architectures_are_the_new_feature_engineering.html">In deep learning, architecture engineering is the new feature engineering</a></li>
              <!--<li><a target="_blank" href="/articles/2015/keras_qa.html">Question answering on the Facebook bAbi dataset using recurrent neural networks and 175 lines of Python + Keras</a></li>-->
              <li><a target="_blank" href="/articles/2015/google_sparsehash.html">How Google Sparsehash achieves two bits of overhead per entry using sparsetable</a></li>
              <li><a target="_blank" href="/articles/2013/where_did_all_the_http_referrers_go.html">Where did all the HTTP referrers go?</a></li>
            </ul>

            <p class="center-text">
              <b>Interested in saying hi? ^_^</b><br />
              <a href="https://twitter.com/Smerity" class="twitter-follow-button" data-size="large" data-show-count="false">Follow @Smerity</a><script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>
              <div class="contact-me">
              <a href="https://www.twitter.com/Smerity/" alt="Twitter"><i class="icon-twitter"></i></a><a href="https://facebook.com/smerity" alt="Facebook"><i class="icon-facebook-sign"></i></a><a href="https://github.com/Smerity/" alt="GitHub"><i class="icon-github"></i></a><a href="http://au.linkedin.com/in/smerity" alt="LinkedIn"><i class="icon-linkedin"></i></a><a href="mailto:smerity@smerity.com" alt="Email"><i class="icon-envelope-alt"></i></a>
              </div>
            </p>

            <div class="well well-small">
              <!--<h1 style="margin-bottom: 0; margin-top: 0; text-align: center;">Hi, I'm Smerity</h1>-->
              <div align="center">
                <!--img class="shadowed pronounced" src="/media/images/smerity_bw.jpg" />-->
              </div>
              <!-- TODO: Place Twitter here -->
              <p>
                I'm <b>Stephen Merity</b>, better known in most places as <b>Smerity</b>.
              </p>
              <p>
                <b>Salesforce Research:</b><br />
                Senior research scientist<br />(deep learning)
              </p>
              <p>
                <b>Part of MetaMind:</b><br />
                Acquired by Salesforce
              </p>
              <p>
                <b>Harvard University:</b><br />
                <a href="http://www.seas.harvard.edu/programs/graduate/computational-science-and-engineering/master-of-science-in-cse">MS in CSE</a>
              </p>
              <p>
                <b>Sydney University:</b><br />
                <a href="http://sydney.edu.au/engineering/it/current_students/undergrad/bit.shtml">BIT</a> (University Medal + First Class Honours)
              </p>
              <p>
                <b><a href="/abme.html">Full about me</a></b>
              </p>
            </div>

            
          </div>
        </div>
      
      </div>
    
    
<footer>
  You reached the bottom! Reading can be challenging, so I think you deserve a reward. I'd offer you <a href="http://www.minecraftwiki.net/wiki/Cake">cake</a>, but after <a href="http://en.wikipedia.org/wiki/Portal_(video_game)">a certain robot-human conflict</a> started due to cake it may not be a wise choice. So here:
  <div align="center">
    <img src="/media/images/mini_coin.png" height="32" width="32" />
  </div>
  Take a coin. No, not a Bitcoin. Do you know how <a title="When I originally put this note here, Bitcoins were only a few dollars each...">expensive</a> those are? ಠ_ಠ
</footer>

  </div>
  
  
  <link rel="stylesheet" type="text/css" href="/media/css/fontawesome/fontawesome.css" />
  <!--[if lt IE 9]>
    <link rel="stylesheet" type="text/css" href="/media/css/fontawesome/fontawesome-ie7.css" />
  <![endif]-->
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,700' rel='stylesheet' type='text/css'>

  
  </body>
</html>